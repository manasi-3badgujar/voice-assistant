# ğŸ¤ Voice Concierge â€“ Browser-Based Hotel Voice Assistant

Voice Concierge is a fully client-side React web application that allows users to interact with a hotel assistant using voice. The application uses native browser Speech-to-Text (STT) and Text-to-Speech (TTS) APIs, responds using rule-based logic, and runs entirely in the browser without any backend or paid services.

---

## ğŸš€ Features Overview

- ğŸ™ï¸ Voice input using browser Speech-to-Text (STT)
- ğŸ”Š Spoken responses using browser Text-to-Speech (TTS)
- ğŸ§  Rule-based intent matching (keyword + fuzzy matching)
- ğŸ’¬ Full conversation display (user + assistant)
- â¯ï¸ Clear Start / Stop microphone control
- ğŸŒ™ Full-page Dark / Light mode
- ğŸ’¾ LocalStorage persistence (chat + analytics)
- âŒ No backend
- âŒ No external or paid APIs
- ğŸŒ Runs fully in the browser

---

## ğŸ›  Tech Stack

- **React** (Vite)
- **Tailwind CSS**
- **Browser SpeechRecognition API**
- **Browser SpeechSynthesis API**
- **LocalStorage**

---

## ğŸ™ How Speech-to-Text (STT) Is Implemented

Speech-to-Text is implemented using the browserâ€™s native `SpeechRecognition` API.

### Flow
1. User clicks the microphone button to start listening.
2. The browser captures audio input via the microphone.
3. Interim transcripts are displayed live while the user is speaking.
4. A final transcript is captured when speech ends.
5. The microphone automatically stops when:
   - Speech is completed
   - No input is detected for 5 seconds
   - The assistant starts speaking

### Notes
- No third-party or paid APIs are used.
- Microphone permission is required.
- Best supported on Chromium-based browsers.

---

## ğŸ”Š How Text-to-Speech (TTS) Is Implemented

Text-to-Speech is implemented using the browserâ€™s native `SpeechSynthesisUtterance` API.

### Flow
1. After intent resolution, the assistant generates a text response.
2. The response is passed to `SpeechSynthesisUtterance`.
3. The browser speaks the response using its default voice.
4. While the assistant is speaking:
   - The microphone is fully disabled
   - User input is blocked
   - A visual â€œAssistant is speakingâ€ indicator is shown

This ensures clean, turn-based interaction between the user and the assistant.

---

## ğŸ§  How Queries Are Matched (Keyword + Fuzzy Search)

The application uses a **rule-based intent matching system**.

### 1. Keyword Matching
Each intent is defined by:
- An intent name
- A list of associated keywords
- A predefined response

**Example**
- Keywords: `food`, `menu`, `order`
- Intent: `food`
- Response: Restaurant information

### 2. Fuzzy Matching
To improve robustness:
- User input is normalized (lowercased, punctuation removed)
- Partial word similarity is calculated
- A confidence score is generated
- Intents above a confidence threshold are selected

### 3. Multi-Intent Handling
If a single query contains multiple valid intents:
- All matched intents are answered in one response
- Duplicate intents within the same query are answered only once

**Example**
> â€œWhatâ€™s the wifi password and gym timing?â€

The assistant responds with both answers.

### 4. Fallback Handling
If no intent meets the confidence threshold:
> â€œIâ€™m sorry, I didnâ€™t understand that. Could you please rephrase?â€

---

## â­ Bonus Features Added

In addition to the required functionality, the following enhancements were implemented:

- ğŸ“Š Analytics panel (total queries, last intent, confidence score)
- ğŸ“ˆ Confidence score display for intent matching
- ğŸ§ User listening waveform animation
- ğŸ”Š Assistant speaking waveform animation
- ğŸ”‡ Automatic microphone blocking while assistant speaks
- â±ï¸ Auto-stop microphone after 5 seconds of silence
- ğŸ’¡ â€œNo input receivedâ€ feedback message
- ğŸ§  Assistant â€œthinking / processingâ€ state before replying
- ğŸ“± Fully responsive UI (mobile & desktop)
- ğŸ¨ Tailwind CSS with gradient-based design

---

## ğŸ’¾ Persistence

- Chat history is stored in `localStorage`
- Analytics data is stored in `localStorage`
- Data is automatically restored on page reload

---

## âš ï¸ Limitations

- Speech recognition accuracy depends on browser and microphone quality
- Best experience on Chrome and Edge
- Safari has partial support
- Firefox support is limited / experimental
- No server-side processing or persistence

---

## â–¶ï¸ Running the Application Locally

```bash
npm install
npm run dev

Then open:

http://localhost:5173

## ğŸš€ Live Demo

https://voice-assistant-mocha-ten.vercel.app/